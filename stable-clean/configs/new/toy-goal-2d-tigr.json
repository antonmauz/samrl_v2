{
    "_info:": "",
    "reconstruction_params": {
        "prior_mode": "network",
	    "reconstruct_all_timesteps": true
    },
    "algo_params": {
        "use_relabeler": true,
        "use_combination_trainer": false,
        "use_data_normalization": true,
        "use_parametrized_alpha": false,
        "encoding_mode": "GRU",
        "use_fixed_seeding": true,
        "seed": 0,
        "batch_size_reconstruction": 4096,
        "batch_size_combination": 256,
        "batch_size_policy": 256,
        "batch_size_relabel": 1024,
        "time_steps": 8,
        "latent_size": 2,
        "sac_layer_size": 300,
        "max_replay_buffer_size": 10000000,
        "data_usage_reconstruction": null,
        "data_usage_sac": null,
        "num_last_samples": 10000000,
        "permute_samples": false,
        "num_train_epochs": 1001,
        "snapshot_gap": 10,
        "num_reconstruction_steps": 128,
        "num_policy_steps": 2048,
        "num_train_tasks_per_episode": 100,
        "num_transitions_initial": 0,
        "num_transitions_per_episode": 200,
        "num_eval_trajectories": 2,
        "showcase_every": 0,
        "num_showcase_deterministic": 1,
        "num_showcase_non_deterministic": 1,
        "max_path_length": 200,
        "target_entropy_factor": 1.0,
        "sac_alpha": 0.2,
        "automatic_entropy_tuning": false
    },
    "env_name": "toy-goal",
    "env_params": {
        "n_eval_tasks": 20,
        "n_train_tasks": 80,
        "task_goal_offset": 0.0,
        "change_mode": "none",
        "random_start": true,
        "goal_1d": false,
        "step_size": 0.05,
        "positive_environment": false,
        "one_side_goals": true,
        "random_policy": false,
        "state_reconstruction_clip": 2,
        "distribution_shift": 0
    }
}
